{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ScBHo1JSr-KR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as f\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "trainset = datasets.MNIST('./MNIST_data', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "valset = datasets.MNIST('./MNIST_data', download=True, train=True, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "tRMRnZFPtBrQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "imagens, etiquetas = dataiter.next()\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "OjJxDKuwuwAe",
        "outputId": "750cf043-2a04-4494-f187-4a68006ab5e7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape) #OBS.: verificar as dimensões do tensor de cada imagem\n",
        "print(etiquetas[0].shape) #OBS.: verificar as dimensões do tenso de cada etiqueta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L2DueIWvRX7",
        "outputId": "640d6310-a8fe-48a7-ff7a-b6af45efe42c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Modelo(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Modelo,self).__init__()\n",
        "    self.linear1 = nn.Linear(28*28, 128)\n",
        "    self.linear2 = nn.Linear(128, 64)\n",
        "    self.linear3 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self,X):\n",
        "    X = F.relu(self.linear1(X))\n",
        "    X = F.relu(self.linear2(X))\n",
        "    X = self.linear1(X)\n",
        "    return F.log_softmax(X, dim=1)"
      ],
      "metadata": {
        "id": "_LelPXqPwu2s"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainloader, device):\n",
        "  otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)\n",
        "  inicio = time()\n",
        "  criterio = nn.NLLLoss()\n",
        "  EPOCHS = 10\n",
        "  modelo.train()\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    perda_acumulada = 0\n",
        "    for imagens, etiquetas in trainloader:\n",
        "      imagens = imagens.view(imagens,shape[0], -1)\n",
        "      otimizador.zero_grad()\n",
        "\n",
        "      output = modelo(imagens.to(device))\n",
        "      perda_instantanea = criterio(output, etiquetas.to(device))\n",
        "\n",
        "      perda_instantanea.backward()\n",
        "\n",
        "      otimizador.step()\n",
        "\n",
        "      perda_acumulada += perda_instantanea.item()\n",
        "\n",
        "    else:\n",
        "      print(\"EPOCH {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "  print(\"\\nTempo de treino (em minutos)=\",(time()-inicio)/60)"
      ],
      "metadata": {
        "id": "wN1nU-9myc9D"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, validador, device):\n",
        "    conta_corretas, conta_todas = 0, 0\n",
        "    for imagens,etiquetas in valloader:\n",
        "      for i in range(len(etiquetas)):\n",
        "        img = imagens[i].view(1, 784)\n",
        "        with torch.no_grad():\n",
        "          logps = modelo(img.to(device))\n",
        "\n",
        "          ps = torch.exp(logps)\n",
        "          probab = list(ps.cpu().numpy()[0])\n",
        "          etiqueta_pred = probab.index(max(probab))\n",
        "          etiqueta_certa = etiquetas.numpy()[i]\n",
        "          if(etiqueta_certa == etiqueta_pred):\n",
        "            conta_corretas +=1\n",
        "          conta_todas +=1\n",
        "\n",
        "      print(\"Total de imagens testadas=\", conta_todas)\n",
        "      print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*100/conta_todas))\n"
      ],
      "metadata": {
        "id": "BJHv_5rZ0-5D"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ak6JOo53YUS",
        "outputId": "c81a7061-50ed-42a8-8af2-a4750e395039"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}